# OWASP Prompt Injection Demo - Environment Configuration
# Copy this file to .env and set your actual values

# ===== LLM API Configuration =====
# Choose ONE LLM provider and set the corresponding API key

# OpenAI Configuration (recommended for demo)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4o-mini
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.7

# Anthropic Configuration (alternative)
# ANTHROPIC_API_KEY=your-anthropic-api-key-here
# ANTHROPIC_MODEL=claude-3-haiku-20240307
# ANTHROPIC_MAX_TOKENS=1000

# Active LLM Provider (openai or anthropic)
LLM_PROVIDER=openai

# ===== Server Configuration =====
BACKEND_PORT=3001
FRONTEND_URL=http://localhost

# ===== Demo Settings =====
# Enable/disable specific features for demo purposes
DEMO_MODE=true
ENABLE_INJECTION_SCENARIOS=true
LOG_LEVEL=debug

# ===== Security Settings =====
# Demo signature validation (set to 'strict' for production-like behavior)
SIGNATURE_VALIDATION=demo

# JWT Secret (for production token validation - not used in demo)
# JWT_SECRET=your-jwt-secret-here

# ===== Attack Scenarios =====
# Configure which injection scenarios are available
ENABLE_CUSTOM_INJECTIONS=true
DEFAULT_INJECTION_COMPLEXITY=medium